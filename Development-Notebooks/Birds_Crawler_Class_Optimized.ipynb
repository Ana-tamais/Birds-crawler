{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCrawler:\n",
    "    \"\"\"\n",
    "    Class of crawler of wikiaves.com.br. \n",
    "    It works with the following approach: It gets a initial link and gather all species names and links to crawl\n",
    "    their information (photo or audio). Then it access the link of all the species you want to crawl and scroll\n",
    "    down the page until there's no more information to be shown. Then it gets all html and save each information \n",
    "    on a directory that it created (if photo, the format is .jpg, if audio, the format is .mp3)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, store_path = '',\n",
    "                 initial_link = 'https://www.wikiaves.com.br/especies.php?t=t',\n",
    "                 photo = True,\n",
    "                 firefox_path = 'geckodriver'):\n",
    "        \n",
    "        self.specie = {}\n",
    "        self.count_photo = {}\n",
    "        self.count_sound = {}\n",
    "        self.path = store_path\n",
    "        self.browser = None\n",
    "        self.soup = None\n",
    "        self.photo = photo\n",
    "        self.num_species = None\n",
    "        self.firefox_path = firefox_path\n",
    "        self.initial_link = initial_link\n",
    "        \n",
    "    def connect_to_internet(self):\n",
    "        firefox_profile = webdriver.FirefoxProfile()\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        self.browser = webdriver.Firefox(firefox_profile=firefox_profile,\n",
    "                                         options=options,\n",
    "                                         executable_path=self.firefox_path)\n",
    "    def get_num_species(self):\n",
    "        self.browser.get(self.initial_link)\n",
    "        html = self.browser.page_source\n",
    "        self.soup = BeautifulSoup(html, 'html.parser')\n",
    "        self.num_species = self.soup.find_all(class_ = 'font-blue-soft')[-1].text[:4]\n",
    "        self.num_species = int(self.num_species)\n",
    "        \n",
    "\n",
    "    \n",
    "    def create_dir_photo(self):\n",
    "        try:\n",
    "            os.mkdir(self.path + '/images')\n",
    "            for specie in range(1, self.num_species + 1):\n",
    "                os.mkdir(self.path + '/images/id_{}'.format(str(10000 + specie)))\n",
    "        except:\n",
    "            print('/images and /images/id_number already exist')\n",
    "        try:\n",
    "            os.mkdir(self.path + '/links_image')\n",
    "        except:\n",
    "            print('/links_image already exist')\n",
    "    \n",
    "    def create_dir_sound(self):\n",
    "        try:\n",
    "            os.mkdir(self.path + '/sounds')\n",
    "            for specie in range(1, self.num_species + 1):\n",
    "                os.mkdir(self.path + '/sounds/id_{}'.format(str(10000 + specie)))\n",
    "        except:\n",
    "            print('/sounds and /sounds/id_number already exist')\n",
    "        try:\n",
    "            os.mkdir(self.path + '/links_sound')\n",
    "        except:\n",
    "            print('/links_sound already exist')\n",
    "    \n",
    "    def create_dir(self):\n",
    "        if self.photo == True:\n",
    "            self.create_dir_photo()\n",
    "        else:\n",
    "            self.create_dir_sound()\n",
    "    \n",
    "    def get_id(self):\n",
    "        for k in range(1, self.num_species+1):\n",
    "            self.count_photo['{}'.format(10000 + k)] = None\n",
    "            self.count_sound['{}'.format(10000 + k)] = None\n",
    "            self.specie['{}'.format(10000 + k)] = None\n",
    "    \n",
    "    def get_image_links(self, id_):\n",
    "        my_filename = os.path.join(self.path + '/links_image/links_{}.txt'.format(id_))\n",
    "        file_photo = open(self.path + '/links_image/links_{}.txt'.format(id_), 'w')\n",
    "        r = requests.get('https://www.wikiaves.com.br/getRegistrosJSON.php?tm=f&t=s&s={}&o=mp&o=mp&p=1'.format(id_))\n",
    "        r = r.json()\n",
    "        self.count_photo['{}'.format(id_)] = r['registros']['total']\n",
    "        self.specie['{}'.format(id_)] = r['registros']['itens']['1']['sp']['idwiki']\n",
    "        pag = 1\n",
    "        while r['registros']['itens'] != {}:\n",
    "            r = requests.get('https://www.wikiaves.com.br/getRegistrosJSON.php?tm=f&t=s&s={}&o=mp&o=mp&p={}'.format(id_, str(pag)))\n",
    "            r = r.json()\n",
    "            for link in range(1, 21):\n",
    "                try:\n",
    "                    file_photo.write(r['registros']['itens']['{}'.format(str(link))]['link'] + '\\n')\n",
    "                except KeyboardInterrupt:\n",
    "                    print('KeyboardInterrupt')\n",
    "                    break\n",
    "                    break\n",
    "                except:\n",
    "                    break\n",
    "            pag += 1\n",
    "        file_photo.close()\n",
    "    \n",
    "    def get_all_image_links(self, ids):\n",
    "        for id_ in ids:\n",
    "            self.get_image_links(id_)\n",
    "            \n",
    "    def get_sound_links(self, id_):\n",
    "        my_filename = os.path.join(self.path + '/links_sound/links_{}.txt'.format(id_))\n",
    "        file_sound = open(my_filename, 'w')\n",
    "        r = requests.get('https://www.wikiaves.com.br/getRegistrosJSON.php?tm=s&t=s&s={}&o=mp&o=mp&p=1'.format(id_))\n",
    "        r = r.json()\n",
    "        self.count_sound['{}'.format(id_)] = r['registros']['total']\n",
    "        self.specie['{}'.format(id_)] = r['registros']['itens']['1']['sp']['idwiki']\n",
    "        pag = 1\n",
    "        while r['registros']['itens'] != {}:\n",
    "            r = requests.get('https://www.wikiaves.com.br/getRegistrosJSON.php?tm=s&t=s&s={}&o=mp&o=mp&p={}'.format(id_, str(pag)))\n",
    "            r = r.json()\n",
    "            for link in range(1, 21):\n",
    "                try:\n",
    "                    file_photo.write(str(r['registros']['itens']['{}'.format(link)]['link'] + '\\n'))\n",
    "                except:\n",
    "                    break\n",
    "            pag += 1\n",
    "        file_sound.close()\n",
    "        \n",
    "    def get_all_sound_links(self, ids):\n",
    "        for id_ in ids:\n",
    "            self.get_sound_links(id_)\n",
    "    \n",
    "    def get_all_links(self, ids):\n",
    "        if self.photo == True:\n",
    "            self.get_all_image_links(ids)\n",
    "        else:\n",
    "            self.get_all_sound_links(ids)\n",
    "    \n",
    "    def save_photo(self, id_):\n",
    "        my_filename = os.path.join(self.path + '/links_image/links_{}.txt'.format(id_))\n",
    "        links = open(my_filename, 'r')\n",
    "        links = links.read()\n",
    "        links = links.split('\\n')[:-1]\n",
    "        i = 1\n",
    "        for link in range(len(links)):\n",
    "            try:\n",
    "                links[link] = links[link].replace('#', 'q')\n",
    "                file_ = os.path.join(self.path + '/images/id_{}/'.format(id_) + '{}_{}.jpg'.format(id_, i))               \n",
    "                urllib.request.urlretrieve(links[link], self.path + '/images/id_{}/'.format(id_) + '{}_{}.jpg'.format(id_, i))\n",
    "            except KeyboardInterrupt:\n",
    "                print('KeyboardInterrupt')\n",
    "                break\n",
    "                break\n",
    "            except:\n",
    "                print('link not added')\n",
    "            i += 1\n",
    "        del links\n",
    "    \n",
    "    def save_all_photos(self, ids):\n",
    "        for id_ in ids:\n",
    "            inicio = time.time()\n",
    "            self.save_photo(id_)\n",
    "            fim = time.time()\n",
    "            print(\"Time = \", fim-inicio)\n",
    "            print(\"Number of photos = \", self.count_photo['{}'.format(id_)])\n",
    "        \n",
    "        \n",
    "    def crawl(self, species):\n",
    "        inicio = time.time()\n",
    "        self.connect_to_internet()\n",
    "        self.get_num_species()\n",
    "        self.create_dir()\n",
    "        self.get_id()\n",
    "        self.get_all_links(species)\n",
    "        self.browser.close()\n",
    "        fim = time.time()\n",
    "        print(fim-inicio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe = BirdCrawler(store_path = '/home/aninha/Documents/Birds_Project', photo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/images and /images/id_number already exist\n",
      "/links_image already exist\n",
      "1058.3048560619354\n"
     ]
    }
   ],
   "source": [
    "classe.crawl(['11644'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link not added\n",
      "link not added\n"
     ]
    }
   ],
   "source": [
    "classe.save_all_photos(['11644'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
