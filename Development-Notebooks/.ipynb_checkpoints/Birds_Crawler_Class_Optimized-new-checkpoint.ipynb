{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "import requests\n",
    "import time\n",
    "import threading\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCrawler:\n",
    "    \"\"\"\n",
    "    Class of crawler of wikiaves.com.br. \n",
    "    It works with the following approach: It gets a initial link and gather all species names and links to crawl\n",
    "    their information (photo or audio). Then it access the link of all the species you want to crawl and scroll\n",
    "    down the page until there's no more information to be shown. Then it gets all html and save each information \n",
    "    on a directory that it created (if photo, the format is .jpg, if audio, the format is .mp3)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, store_path = '',\n",
    "                 initial_link = 'https://www.wikiaves.com.br/especies.php?t=t',\n",
    "                 photo = True,\n",
    "                 firefox_path = 'geckodriver'):\n",
    "        \n",
    "        self.specie = {}\n",
    "        self.count_photo = {}\n",
    "        self.path = store_path\n",
    "        self.browser = None\n",
    "        self.soup = None\n",
    "        self.photo = photo\n",
    "        self.num_species = None\n",
    "        self.firefox_path = firefox_path\n",
    "        self.initial_link = initial_link\n",
    "        self.my_filename = {}\n",
    "        self.file_photo = {}\n",
    "        self.r = {}\n",
    "        self.pag = {}\n",
    "        self.count = {}\n",
    "        \n",
    "    def connect_to_internet(self):\n",
    "        firefox_profile = webdriver.FirefoxProfile()\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        self.browser = webdriver.Firefox(firefox_profile=firefox_profile,\n",
    "                                         options=options,\n",
    "                                         executable_path=self.firefox_path)\n",
    "    def get_num_species(self):\n",
    "        self.browser.get(self.initial_link)\n",
    "        html = self.browser.page_source\n",
    "        self.soup = BeautifulSoup(html, 'html.parser')\n",
    "        self.num_species = self.soup.find_all(class_ = 'font-blue-soft')[-1].text[:4]\n",
    "        self.num_species = int(self.num_species)\n",
    "        \n",
    "\n",
    "    \n",
    "    def create_dir(self):\n",
    "        try:\n",
    "            os.mkdir(self.path + '/images')\n",
    "            for specie in range(1, self.num_species + 1):\n",
    "                os.mkdir(self.path + '/images/id_{}'.format(str(10000 + specie)))\n",
    "        except:\n",
    "            print('/images and /images/id_number already exist')\n",
    "        try:\n",
    "            os.mkdir(self.path + '/links_image')\n",
    "        except:\n",
    "            print('/links_image already exist')\n",
    "\n",
    "    \n",
    "    def get_id(self):\n",
    "        for k in range(1, self.num_species+1):\n",
    "            self.count_photo['{}'.format(10000 + k)] = None\n",
    "            self.specie['{}'.format(10000 + k)] = None\n",
    "            \n",
    "    def create_dependencies(self, id_):\n",
    "        self.my_filename['{}'.format(id_)] = os.path.join(self.path + '/links_image/links_{}.txt'.format(id_))\n",
    "        self.file_photo['{}'.format(id_)] = open(self.path + '/links_image/links_{}.txt'.format(id_), 'w')\n",
    "        self.r['{}'.format(id_)] = requests.get('https://www.wikiaves.com.br/getRegistrosJSON.php?tm=f&t=s&s={}&o=mp&o=mp&p=1'.format(id_))\n",
    "        self.r['{}'.format(id_)] = self.r['{}'.format(id_)].json()\n",
    "        \n",
    "    def get_image_links(self, id_):\n",
    "        self.create_dependencies(id_)\n",
    "        self.count_photo['{}'.format(id_)] = self.r['{}'.format(id_)]['registros']['total']\n",
    "        try:\n",
    "            self.specie['{}'.format(id_)] = self.r['{}'.format(id_)]['registros']['itens']['1']['sp']['idwiki']\n",
    "        except:\n",
    "            print(\"no image, id = \", id_)\n",
    "        self.pag['{}'.format(id_)] = 1\n",
    "        while self.r['{}'.format(id_)]['registros']['itens'] != {}:\n",
    "            self.r['{}'.format(id_)] = requests.get('https://www.wikiaves.com.br/getRegistrosJSON.php?tm=f&t=s&s={}&o=mp&o=mp&p={}'.format(id_, str(self.pag['{}'.format(id_)])))\n",
    "            self.r['{}'.format(id_)] = self.r['{}'.format(id_)].json()\n",
    "            self.count['{}'.format(id_)] = 1\n",
    "            while self.count['{}'.format(id_)] < 22:\n",
    "                try:\n",
    "                    self.file_photo['{}'.format(id_)].write(\"[\" + self.r['{}'.format(id_)]['registros']['itens']['{}'.format(str(self.count['{}'.format(id_)]))]['link'].replace('#', 'q') + ', {}]'.format(id_) + '\\n')\n",
    "                except KeyboardInterrupt:\n",
    "                    print('KeyboardInterrupt')\n",
    "                    break\n",
    "                    break\n",
    "                except:\n",
    "                    break\n",
    "                self.count['{}'.format(id_)] += 1\n",
    "            self.pag['{}'.format(id_)] += 1\n",
    "        self.file_photo['{}'.format(id_)].close()\n",
    "    \n",
    "    def get_all_links(self, ids):\n",
    "        for id_ in ids:\n",
    "            self.get_image_links(id_)\n",
    "\n",
    "    \n",
    "    def save_photo(self, id_):\n",
    "        my_filename = os.path.join(self.path + '/links_image/links_{}.txt'.format(id_))\n",
    "        links = open(my_filename, 'r')\n",
    "        links = links.read()\n",
    "        links = links.split('\\n')[:-1]\n",
    "        i = 1\n",
    "        for link in range(len(links)):\n",
    "            try:\n",
    "                links[link] = links[link].replace('#', 'q')\n",
    "                file_ = os.path.join(self.path + '/images/id_{}/'.format(id_) + '{}_{}.jpg'.format(id_, i))               \n",
    "                urllib.request.urlretrieve(links[link], self.path + '/images/id_{}/'.format(id_) + '{}_{}.jpg'.format(id_, i))\n",
    "            except KeyboardInterrupt:\n",
    "                print('KeyboardInterrupt')\n",
    "                break\n",
    "                break\n",
    "            except:\n",
    "                print('link not added')\n",
    "            i += 1\n",
    "        del links\n",
    "    \n",
    "    def save_all_photos(self, ids):\n",
    "        for id_ in ids:\n",
    "            inicio = time.time()\n",
    "            self.save_photo(id_)\n",
    "            fim = time.time()\n",
    "            print(\"Time = \", fim-inicio)\n",
    "            print(\"Number of photos = \", self.count_photo['{}'.format(id_)])\n",
    "        \n",
    "    def crawl(self, species):\n",
    "        inicio = time.time()\n",
    "        self.connect_to_internet()\n",
    "        self.get_num_species()\n",
    "        self.create_dir()\n",
    "        self.get_id()\n",
    "        self.get_all_links(species)\n",
    "        self.browser.close()\n",
    "        fim = time.time()\n",
    "        print(fim-inicio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_thread(ids):\n",
    "    classes = {}\n",
    "    ids_species = []\n",
    "    for id_ in range(int(ids[0]), int(ids[0]) + 316):\n",
    "        ids_species.append(str(id_))\n",
    "\n",
    "    threads = []\n",
    "    for id_ in range(0, len(ids_species), 3):\n",
    "        classes['{}'.format(id_)] = BirdCrawler(store_path = '/home/aninha/Documents/Birds_Project')\n",
    "        threads.append(threading.Thread(target=classes['{}'.format(id_)].get_all_links, args = ([str(ids_species[id_]), \n",
    "                                                                                                 str(int(ids_species[id_]) + 1), \n",
    "                                                                                                 str(int(ids_species[id_]) + 2),],)))\n",
    "    for i in threads:\n",
    "        i.start()\n",
    "    for i in threads:\n",
    "        i.join()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_thread(['10001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
