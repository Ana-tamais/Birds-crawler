{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json \n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from PIL import Image  \n",
    "import PIL\n",
    "import statistics\n",
    "import re\n",
    "import urllib\n",
    "from selenium.webdriver.firefox.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCrawler:\n",
    "    \"\"\"\n",
    "    store_path: onde armazena as imagens crawladas\n",
    "    initial_link: link inicial da wikiaves\n",
    "    bird_link_list_photo: lista de links para fotos de cada espécie\n",
    "    bird_link_list_sound: lista de links para áudios de cada espécie\n",
    "    species_list = lista de todas as espécies\n",
    "    num_photo: lista do número de fotos por espécie\n",
    "    num_sound: lista do número de áudios por espécie\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, store_path = '', \n",
    "                 initial_link_photo = \"https://www.wikiaves.com.br/especies.php?t=t&o=5\", \n",
    "                 initial_link_sound = \"https://www.wikiaves.com.br/especies.php?t=t&o=4\",\n",
    "                 photo = True):\n",
    "        self.bird_link_list_photo = [] \n",
    "        self.bird_link_list_sound = []\n",
    "        self.species_list = []\n",
    "        self.path = store_path\n",
    "        if photo == True:\n",
    "            self.initial_link = initial_link_photo\n",
    "        else:\n",
    "            self.initial_link = initial_link_sound\n",
    "        self.num_photo = []\n",
    "        self.num_sound = []\n",
    "        self.browser = None\n",
    "        self.soup = None\n",
    "        self.photo = photo\n",
    "        \n",
    "    def connect_to_internet(self):\n",
    "        firefox_profile = webdriver.FirefoxProfile()\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        self.browser = webdriver.Firefox(firefox_profile = firefox_profile, options = options)\n",
    "    \n",
    "    def get_list_link_num(self):\n",
    "        for especie in self.soup.find_all(class_=\"font-blue\"):\n",
    "            if especie.get('href') is not None and (\"https://www.wikiaves.com.br/\" + especie.get('href'))[42] == \"f\":\n",
    "                self.bird_link_list_photo.append(\"https://www.wikiaves.com.br/\" + especie.get('href'))\n",
    "                self.num_photo.append(especie.text)\n",
    "            elif especie.get('href') is not None and (\"https://www.wikiaves.com.br/\" + especie.get('href'))[42] == \"s\":\n",
    "                self.bird_link_list_sound.append(\"https://www.wikiaves.com.br/\" + especie.get('href'))\n",
    "                self.num_sound.append(especie.text)\n",
    "\n",
    "            \n",
    "    def get_species(self):\n",
    "        for especie in self.soup.find_all(class_=\"font-green-dark\"):\n",
    "            if especie.text not in self.species_list:\n",
    "                self.species_list.append(especie.text)\n",
    "        \n",
    "                \n",
    "    def get_information(self):\n",
    "        self.browser.get(self.initial_link)\n",
    "        html = self.browser.page_source\n",
    "        self.soup = BeautifulSoup(html, \"html.parser\")\n",
    "        self.get_list_link_num()\n",
    "        self.get_species()\n",
    "        \n",
    "    def create_dir(self):\n",
    "        os.mkdir(self.path + \"/images\")\n",
    "        os.mkdir(self.path + '/sounds')\n",
    "        for especie in self.species_list:\n",
    "            os.mkdir(self.path + \"/images/{}\".format(especie))\n",
    "            os.mkdir(self.path + \"/sounds/{}\".format(especie))\n",
    "    \n",
    "    def export_links_to_txt(self):\n",
    "        file_photo = open(self.path + \"/links_photo.txt\", \"w\")\n",
    "        for k in range(len(self.bird_link_list_photo)):\n",
    "            file_photo.write(self.bird_link_list_photo[k] + \"\\n\")\n",
    "            \n",
    "        file_sound = open(\"links_sound.txt\", \"w\")\n",
    "        for k in range(len(self.bird_link_list_sound)):\n",
    "            file_sound.write(self.bird_link_list_sound[k] + \"\\n\")\n",
    "    \n",
    "    def import_links_from_txt(self):\n",
    "        links_photo = open(self.path +\"/links_photo.txt\", \"r\")\n",
    "        links_photo = links_photo.read()\n",
    "        links_photo = links_photo.split(\"\\n\")[:-1]\n",
    "        \n",
    "        links_sound = open(self.path + \"/links_sound.txt\", \"r\")\n",
    "        links_sound = links_sound.read()\n",
    "        links_sound = links_sound.split(\"\\n\")[:-1]\n",
    "        \n",
    "        return links_photo, links_sound\n",
    "        \n",
    "    def crawl_one_photo_link(self, especie):\n",
    "        list_links = self.import_links_from_txt()[0]\n",
    "        for k in range(len(self.species_list)):\n",
    "            if self.species_list[k] in especie:\n",
    "                print(list_links[k])\n",
    "                self.browser.get(list_links[k])\n",
    "                i = 0\n",
    "                for j in range(1000000):\n",
    "                    if j % 10 == 0:\n",
    "                        html = self.browser.page_source\n",
    "                        self.soup = BeautifulSoup(html, 'html.parser')\n",
    "                        imagens = self.soup.find_all(class_ = \"img-responsive\")\n",
    "                        del html\n",
    "                        self.soup = None\n",
    "                    if len(imagens) >= int(self.num_photo[k]):\n",
    "                        break\n",
    "                    if j % 100 == 0:\n",
    "                        print(j)\n",
    "                    self.browser.execute_script(\"window.scrollTo(0, {})\".format(2000 + i))\n",
    "                    i += 2000\n",
    "                self.save_images(self.browser, especie)\n",
    "    \n",
    "    def crawl_one_audio_link(self, especie):\n",
    "        list_links = self.import_links_from_txt()[1]\n",
    "        for k in range(len(self.species_list)):\n",
    "            if self.species_list[k] in especie:\n",
    "                print(list_links[k])\n",
    "                self.browser.get(list_links[k])\n",
    "                i = 0\n",
    "                for j in range(1000000):\n",
    "                    if j % 100 == 0:\n",
    "                        html = self.browser.page_source\n",
    "                        self.soup = BeautifulSoup(html, 'html.parser')\n",
    "                        sounds = self.soup.find_all(class_ = 'mejs-container svg wikiaves-player progression-single progression-skin progression-minimal-dark progression-audio-player mejs-audio')\n",
    "                        del html\n",
    "                        self.soup = None\n",
    "                    if len(sounds) >= int(self.num_sound[k]):\n",
    "                        break\n",
    "                    if j % 100 == 0:\n",
    "                        print(j)\n",
    "                    self.browser.execute_script(\"window.scrollTo(0, {})\".format(2000 + i))\n",
    "                    i += 2000\n",
    "                self.save_sounds(self.browser, especie)\n",
    "    \n",
    "    def save_sounds(self, browser, especie):\n",
    "        html = browser.page_source\n",
    "        self.soup = BeautifulSoup(html, 'html.parser')\n",
    "        sounds = self.soup.find_all(class_ = 'mejs-container svg wikiaves-player progression-single progression-skin progression-minimal-dark progression-audio-player mejs-audio')\n",
    "        for sound in range(len(sounds)):\n",
    "            try:\n",
    "                save = sounds[sound]['src']\n",
    "                my_filename = os.path.join(self.path + \"/sounds/{}/\".format(especie) + \"{}{}.mp3\".format(especie, sound))\n",
    "                with open(my_filename, 'w') as handle:\n",
    "                    print(file=handle)\n",
    "                urllib.request.urlretrieve(save, self.path + '/sounds/{}/'.format(especie) + '{}{}.mp3'.format(especie, sound))\n",
    "                del html\n",
    "                self.soup = None\n",
    "                del sounds\n",
    "            except:\n",
    "                a = 'a'\n",
    "    def save_images(self, browser, especie):\n",
    "        html = browser.page_source\n",
    "        self.soup = BeautifulSoup(html, 'html.parser')\n",
    "        imagens = self.soup.find_all(class_ = 'img-responsive')\n",
    "        for imagem in range(len(imagens)):\n",
    "            save = imagens[imagem]['src']\n",
    "            my_filename = os.path.join(self.path + \"/images/{}/\".format(especie) + '{}{}.jpg'.format(especie, imagem))\n",
    "            with open(my_filename, \"w\")as handle:\n",
    "                print(file=handle)\n",
    "            urllib.request.urlretrieve(save, self.path + \"/images/{}/\".format(especie) + '{}{}.jpg'.format(especie, imagem))\n",
    "        del html\n",
    "        self.soup = None\n",
    "        del imagens\n",
    "    \n",
    "    def crawl_lots_of_photo_links(self, especies):\n",
    "        for especie in especies:\n",
    "            self.crawl_one_photo_link(especie)\n",
    "        \n",
    "    def crawl_lots_of_sound_links(self, especies):\n",
    "        for especie in especies:\n",
    "            self.crawl_one_audio_link(especie)\n",
    "            \n",
    "    def main(self, especies):\n",
    "        print(\"Starting program...\")\n",
    "        self.connect_to_internet()\n",
    "        print(\"Connected to internet!\")\n",
    "        self.get_information()\n",
    "        print(\"All information was collected!\")\n",
    "        try:\n",
    "            self.create_dir()\n",
    "        except:\n",
    "            a = 'a'\n",
    "        print(\"All directories was created\")\n",
    "        self.export_links_to_txt()\n",
    "        print(\"Exported links to txt!\")\n",
    "        if self.photo == True:\n",
    "            self.crawl_lots_of_photo_links(especies)\n",
    "            print(\"All photos was crawled\")\n",
    "        else:\n",
    "            self.crawl_lots_of_sound_links(especies)\n",
    "            print(\"All sounds was crawled\")\n",
    "        self.browser.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe = BirdCrawler(store_path = '/home/aninha/Documents/Birds_Project', photo = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting program...\n",
      "Connected to internet!\n",
      "All information was collected!\n",
      "All directories was created\n",
      "Exported links to txt!\n",
      "https://www.wikiaves.com.br/midias.php?tm=s&t=s&s=11291\n",
      "All sounds was crawled\n"
     ]
    }
   ],
   "source": [
    "classe.main([\"colegial\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
